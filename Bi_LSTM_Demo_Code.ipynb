{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AywuukroYtkA",
        "outputId": "92882529-8338-48a8-9821-f00997d8a1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the model file,\n",
        "model_path = '/content/drive/My Drive/bilstm_model.h5'\n",
        "\n",
        "# Loading the model\n",
        "model = load_model(model_path)\n",
        "\n",
        "with open('/content/drive/My Drive/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "with open('/content/drive/My Drive/max_seq_length.pkl', 'rb') as f:\n",
        "    max_seq_length = pickle.load(f)"
      ],
      "metadata": {
        "id": "ILyUkDBmrYJc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess text data from a CSV file\n",
        "def load_and_preprocess_data(filepath):\n",
        "    # Read data from CSV file at 'filepath' into a DataFrame\n",
        "    data = pd.read_csv(filepath)\n",
        "    # Handle possible NaN values by converting them to string\n",
        "    data.fillna('', inplace=True)\n",
        "    # Combine 'Claim' and 'Evidence' columns into a single string per row for processing\n",
        "    texts = []\n",
        "    for index, row in data.iterrows():\n",
        "        try:\n",
        "            combined_text = str(row['Claim']) + \" \" + str(row['Evidence'])\n",
        "            texts.append(combined_text)\n",
        "        except AttributeError as e:\n",
        "            print(f\"Error processing row {index}: {row['Claim']}, {row['Evidence']}\")\n",
        "            raise e\n",
        "\n",
        "    return texts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xXo3YB67aU_Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_csv(path):\n",
        "    # Load and preprocess test data in a similar fashion as training data\n",
        "    test_texts = load_and_preprocess_data(path)\n",
        "    test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "    test_data = pad_sequences(test_sequences, maxlen=max_seq_length)\n",
        "    # Generate predictions for the validation set\n",
        "    test_predictions = model.predict(test_data)\n",
        "    # Convert probabilities to binary labels (0 or 1) based on a 0.5 threshold\n",
        "    test_predicted_labels = (test_predictions > 0.5).astype(int)\n",
        "\n",
        "    # Create a DataFrame with the predicted labels\n",
        "    predictions_df = pd.DataFrame(test_predicted_labels, columns=['prediction'])\n",
        "\n",
        "    # Save the predictions to a CSV file\n",
        "    predictions_df.to_csv('test_predictions.csv', index=False)\n",
        "\n",
        "path = '/content/test.csv'\n",
        "predict_from_csv(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOTY71U-am78",
        "outputId": "0a53d9f3-cec7-4e83-e5c9-47eef1a05ceb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 46s 315ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_claim_evidence(claim, evidence):\n",
        "    tokenizer = Tokenizer(num_words=5000)\n",
        "    # Combine claim and evidence into a single input string\n",
        "    combined_input = claim + \" \" + evidence  # Modify this if your model expects a different format\n",
        "\n",
        "    # Tokenize and pad the input\n",
        "    input_sequence = tokenizer.texts_to_sequences([combined_input])\n",
        "    padded_input = pad_sequences(input_sequence, maxlen=277)\n",
        "\n",
        "    # Predict the output\n",
        "    prediction = model.predict(padded_input)\n",
        "\n",
        "    # Convert prediction probability to True or False\n",
        "    is_true = (prediction > 0.5).astype(bool)\n",
        "\n",
        "    return is_true[0, 0]  # Adjust indexing based on how your model outputs predictions\n",
        "\n",
        "# Example usage\n",
        "claim = \"The capital of France is Paris.\"\n",
        "evidence = \"Paris has been the capital of France since the 6th century.\"\n",
        "result = predict_claim_evidence(claim, evidence)\n",
        "print(\"The claim is\", \"true\" if result else \"false\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XEKWeJ9c38_",
        "outputId": "a38f03de-a221-4da3-e30b-f0e0d6f2b413"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 228ms/step\n",
            "The claim is true\n"
          ]
        }
      ]
    }
  ]
}